# (Q) Discuss why the trip data can only be seen as a proxy for the true demand
# (A) The dataset records 'observed trips', which is the number of bikes actually checked out (picked up) in a given hour from one specific zone.
# However, true demand refers to the number of people who 'wanted' to rent a bike, regardless of whether they succeeded (got to rent a bike).
# As we do not know the number of bikes present at each specific zone, the number of trips observed in the data does not perfectly equal the number of people who wanted to ride. 
# The observed counts are instead a realized outcome constrained by supply, access, and user behavior.

# Clear workspace
#rm(list = ls())

# Load libraries
library(dplyr)
library(lubridate)
library(ggplot2)
library(zoo)
library(tseries)
library(forecast)
library(urca)
library(MCS)

# Load the data (adjust the path if needed)
#getwd()
#load("citibike.RData")

# ============================================================
# DATA Exploration
# ===========================================================
# Check structure
str(citibike)
summary(citibike)
head(citibike)

# Make dataset a dataframe
citibike <- as.data.frame(citibike)
print(tail(citibike$datetime))
# Convert to proper time format
citibike <- citibike %>%
  mutate(
    datetime = make_datetime(year, month, day, hour)
  ) %>%
  arrange(datetime)

# Plot the demand time series'
ggplot(citibike, aes(x = datetime, y = demand)) +
  geom_line() +
  labs(title = "Hourly Citi Bike Demand (Jan–May 2023)",
       x = "Time", y = "Demand")

# Seasonality
# Hour of Day
citibike %>%
  group_by(hour) %>%
  summarise(avg_demand = mean(demand)) %>%
  ggplot(aes(x = hour, y = avg_demand)) +
  geom_line() +
  labs(title = "Average Hourly Demand Pattern",
       x = "Hour of Day", y = "Average Demand")

# Conclusion: Morning and Evening peaks

# Day of Week
citibike %>%
  group_by(wkday) %>%
  summarise(avg_demand = mean(demand)) %>%
  ggplot(aes(x = wkday, y = avg_demand)) +
  geom_line() +
  labs(title = "Day-of-Week Pattern",
       x = "Weekday (1=Mon, 7=Sun)", y = "Average Demand")
# Conclusion: In the weekend bikes are rented less than during the working days.

# Monthly
citibike %>%
  group_by(month) %>%
  summarise(avg_demand = mean(demand)) %>%
  ggplot(aes(x = month, y = avg_demand)) +
  geom_line() +
  labs(title = "Average Monthly Demand",
       x = "Month", y = "Demand")

# Conclusion: In May people are renting much more bikes than in January.

citibike$roll_mean <- rollmean(citibike$demand, k = 24*7, fill = NA)
citibike$roll_sd   <- rollapply(citibike$demand, 24*7, sd, fill = NA)

ggplot(citibike, aes(datetime)) +
  geom_line(aes(y = demand), alpha = 0.4) +
  geom_line(aes(y = roll_mean), color = "red") +
  labs(title = "Demand with 1-Week Rolling Mean")


# Prepare training sample
# training sample: Jan 1 – Apr 30
train <- citibike %>% filter(month <= 4)

# extract without seasonality
train_ts_plain <- ts(as.numeric(as.vector(train$demand)))  

# extract the demand series as a ts object with daily seasonality
train_ts_seasonal <- ts(as.numeric(as.vector(train$demand)), frequency = 24)  
# frequency = 24 -> daily

#------------------------------
# Differencing for ARIMA (no seasonality)
#------------------------------
#if you want to see entire output of test instead of justing using forecast package:
#ADF and KPSS for non-seasonal d (not yet seasonal differencing)
adf_res <- ur.df(citibike$demand, type="none", selectlags="AIC")
print(summary(adf_res))
kpss_test <- ur.kpss(citibike$demand, type="mu")
print(summary(kpss_test))

#Automatic recommendation for d (non-seasonal only)
adf.test(citibike$demand)
d_nonseasonal <- ndiffs(citibike$demand, test="kpss")
cat("Chosen non-seasonal differencing (ARIMA): d =", d_nonseasonal, "\n")

#Plot acf and pacf for at most 50 hours (little over 2 days)
max_lag <- 50
acf(train_ts_seasonal, lag.max = max_lag, main = "ACF of Demand", xlab = "Lag")
pacf(train_ts_seasonal, lag.max = max_lag, main = "PACF of Demand", xlab = "Lag")

#compute values shown in the plot:
acf_values <- acf(train_ts_seasonal, lag.max = max_lag, plot = FALSE)
acf_values$acf  

#compute PACF values shown in the plot:
pacf_values <- pacf(train_ts_seasonal, lag.max = max_lag, plot = FALSE)
pacf_values$acf  

# -------------------------------
# Manual Non-Seasonal ARIMA Models
# -------------------------------
#note that we obtained 1 for differencing, so for new models we plug in 1 in combination with AR and MA values 1 or 2.
#Model 1: ARIMA(1,1,1)
arima_111 <- Arima(train_ts_plain, order = c(1,1,1), seasonal = FALSE)
summary(arima_111)

#Model 2: ARIMA(2,1,1)
arima_211 <- Arima(train_ts_plain, order = c(2,1,1), seasonal = FALSE)
summary(arima_211)

#Model 3: ARIMA(1,1,2)
arima_112 <- Arima(train_ts_plain, order = c(1,1,2), seasonal = FALSE)
summary(arima_112)

# Compare AIC/BIC
aic_values <- c(
  ARIMA_111 = AIC(arima_111),
  ARIMA_211 = AIC(arima_211),
  ARIMA_112 = AIC(arima_112)
)
bic_values <- c(
  ARIMA_111 = BIC(arima_111),
  ARIMA_211 = BIC(arima_211),
  ARIMA_112 = BIC(arima_112)
)

model_compare_nonseasonal <- data.frame(
  Model = names(aic_values),
  AIC = round(aic_values,2),
  BIC = round(bic_values,2)
)
print("Non-Seasonal ARIMA Model Comparison:")
print(model_compare_nonseasonal)

#run residual diagnostics
par(mfrow=c(3,2))
checkresiduals(arima_111)
checkresiduals(arima_211)
checkresiduals(arima_112)
par(mfrow=c(1,1))

# -------------------------------
# Automatic Non-Seasonal ARIMA
# -------------------------------
auto_arima_nonseasonal <- auto.arima(train_ts_plain, seasonal = FALSE)
summary(auto_arima_nonseasonal)

# Compare manual vs automatic
aic_auto <- AIC(auto_arima_nonseasonal)
bic_auto <- BIC(auto_arima_nonseasonal)
print(paste("Automatic ARIMA: AIC =", round(aic_auto,2), ", BIC =", round(bic_auto,2)))

#-----------------------
# SARIMA manual
#----------------------------------

#seasonal differencing D using Canova–Hansen from Hyndman and Kandahar
D <- nsdiffs(train_ts_seasonal, test="ch")
cat("Seasonal differencing D =", D, "\n")

#so conclude seasonal differencing is D=0 and non-seasonal is d=1
#Model 1: (1,1,2)(1,0,1) daily seasonality
sarima_112_101 <- Arima(
  train_ts_seasonal,
  order = c(1, 1, 2),
  seasonal = list(order = c(1, 0, 1), period = 24)
)
summary(sarima_112_101)

#Model 2: (2,1,1)(1,0,1) daily seasonality
sarima_211_101 <- Arima(
  train_ts_seasonal,
  order = c(2, 1, 1),
  seasonal = list(order = c(1, 0, 1), period = 24)
)
summary(sarima_211_101)


#-----------------------
# SARIMA auto
#----------------------------------

auto_sarima <-auto.arima(train_ts_seasonal,
                         seasonal = TRUE,
                         stepwise = TRUE,
                         approximation = TRUE,
                         max.p = 3, max.q = 3,
                         max.P = 2, max.Q = 2)
summary(auto_sarima)


#compare AIC/BIC
AIC(sarima_112_101, sarima_211_101, auto_sarima)
BIC(sarima_112_101, sarima_211_101, auto_sarima)

#residual diagnostics
checkresiduals(sarima_112_101)
checkresiduals(sarima_211_101)
checkresiduals(auto_sarima)

##======================
# Exponential smoothing 
#=======================
ets_model <- ets(train_ts_seasonal)
#note that ets model selects model with lowest AIC 

summary(ets_model)

#try some pre-mode plots of the tree components of ets model (level, trend, seasonal)
plot(ets_model)
autoplot(ets_model)


#find right seasonal columns (exclude level)
seasonal_cols <- setdiff(colnames(ets_model$states), "l")
seasonal_matrix <- ets_model$states[, seasonal_cols]
m <- frequency(train_ts_seasonal)

par(mfrow=c(1,1))
#take the first row of seasonal states, that is the initial seasonal cycle
seasonal_cycle <- as.numeric(seasonal_matrix[1, 1:m])
plot(
  seasonal_cycle,
  type = "l",
  xlab = "Hour of Day",
  ylab = "Seasonal Effect",
  main = paste("Initial Daily Seasonal Component (m =", m, ")")
)


# ============================================================
# In-Sample Model Comparison
# ============================================================
models <- list(
  ARIMA_111 = arima_111,
  ARIMA_211 = arima_211,
  ARIMA_112 = arima_112,
  SARIMA_112_101 = sarima_112_101,
  SARIMA_211_101 = sarima_211_101,
  SARIMA_auto = auto_sarima,
  ETS = ets_model
)

# ----------- AIC & BIC TABLE -----------
aic_values <- sapply(models, AIC)
bic_values <- sapply(models, BIC)
loglik_values <- sapply(models, logLik)

model_compare <- data.frame(
  Model = names(models),
  AIC = round(aic_values, 2),
  BIC = round(bic_values, 2),
  LogLik = round(loglik_values, 2)
)

print("=== AIC/BIC/LogLik Comparison ===")
print(model_compare)


# ============================================================
# Out-of-Sample Model Forecasts
# ============================================================

#function to prevent negative forecasts
no_negative <- function(x) { x[x < 0] <- 0; x }

#prevent error such that we just get NA
safe_fit <- function(model_fun, ts_data) {
  fit <- try(model_fun(ts_data), silent = TRUE)
  if (inherits(fit, "try-error")) return(NULL)
  fit
}

#rolling forecast function
rolling <- function(model_fun, ts_full, n_train_hours, n_test_days, seasonal=FALSE) {
  rolling_fc <- matrix(NA, nrow = n_test_days, ncol = 24)
  #print(model_fun)
  for (i in 1:n_test_days) {
    #constant sample size: include 1 new day of forecast every loop
    start_idx <- (i - 1) * 24 + 1
    end_idx   <- start_idx + n_train_hours - 1
    
    train_roll <- ts_full[start_idx:end_idx]
    train_ts   <- if (seasonal) ts(train_roll, frequency = 24) else ts(train_roll)
    
    fit <- safe_fit(model_fun, train_ts)
    if (is.null(fit)) { rolling_fc[i, ] <- rep(NA, 24); next }
    
    fc <- forecast(fit, h = 24)$mean
    #no negative forecasts
    rolling_fc[i, ] <- no_negative(fc)
  }
  rolling_fc
}

#expanding forecast function
expanding <- function(model_fun, ts_full, n_train_hours, n_test_days, seasonal=FALSE) {
  expanding_fc <- matrix(NA, nrow = n_test_days, ncol = 24)
  
  for (i in 1:n_test_days) {
    #only extend sample size: include 1 new day of forecast every loop
    end_idx <- n_train_hours + (i - 1) * 24
    train_expand <- ts_full[1:end_idx]
    train_ts <- if (seasonal) ts(train_expand, frequency = 24) else ts(train_expand)
    
    fit <- safe_fit(model_fun, train_ts)
    if (is.null(fit)) { expanding_fc[i, ] <- rep(NA, 24); next }
    
    fc <- forecast(fit, h = 24)$mean
    #no negative forecasts
    expanding_fc[i, ] <- no_negative(fc)
  }
  expanding_fc
}

#Define test data and sample sizes for non-differenced sample
ts_full <- citibike$demand
test_data <- citibike %>% filter(month == 5)
n_test_days <- length(unique(test_data$day))
n_train_hours <- length(train_ts_seasonal)

#collect all non-fitted models as functions
ARIMA_111_fun <- function(ts_data) Arima(ts_data, order=c(1,1,1), seasonal=FALSE)
ARIMA_211_fun <- function(ts_data) Arima(ts_data, order=c(2,1,1), seasonal=FALSE)
ARIMA_112_fun <- function(ts_data) Arima(ts_data, order=c(1,1,2), seasonal=FALSE)
ARIMA_auto_fun <- function(ts_data) auto.arima(ts_data, seasonal=FALSE)

SARIMA_112_101_fun <- function(ts_data) Arima(ts_data, order=c(1,1,2), seasonal=list(order=c(1,0,1), period=24))
SARIMA_211_101_fun <- function(ts_data) Arima(ts_data, order=c(2,1,1), seasonal=list(order=c(1,0,1), period=24))
SARIMA_auto_fun <- function(ts_data) auto.arima(ts_data, seasonal=TRUE,  stepwise = TRUE,
                                                approximation = TRUE,
                                                max.p = 3, max.q = 3,
                                                max.P = 2, max.Q = 2)

ETS_fun <- function(ts_data) ets(ts_data)

#store rolling forecasts results
rolling_results <- list(
  ARIMA_111 = rolling(ARIMA_111_fun, ts_full, n_train_hours, n_test_days, FALSE),
  ARIMA_211 = rolling(ARIMA_211_fun, ts_full, n_train_hours, n_test_days, FALSE),
  ARIMA_112 = rolling(ARIMA_112_fun, ts_full, n_train_hours, n_test_days, FALSE),
  ARIMA_auto = rolling(ARIMA_auto_fun, ts_full, n_train_hours, n_test_days, FALSE),
  
  SARIMA_112_101 = rolling(SARIMA_112_101_fun, ts_full, n_train_hours, n_test_days, TRUE),
  SARIMA_211_101 = rolling(SARIMA_211_101_fun, ts_full, n_train_hours, n_test_days, TRUE),
  SARIMA_auto = rolling(SARIMA_auto_fun, ts_full, n_train_hours, n_test_days, TRUE),
  
  ETS = rolling(ETS_fun, ts_full, n_train_hours, n_test_days, TRUE)
)

#store expanding forecasts results
expanding_results <- list(
  ARIMA_111 = expanding(ARIMA_111_fun, ts_full, n_train_hours, n_test_days, FALSE),
  ARIMA_211 = expanding(ARIMA_211_fun, ts_full, n_train_hours, n_test_days, FALSE),
  ARIMA_112 = expanding(ARIMA_112_fun, ts_full, n_train_hours, n_test_days, FALSE),
  ARIMA_auto = expanding(ARIMA_auto_fun, ts_full, n_train_hours, n_test_days, FALSE),
  
  SARIMA_112_101 = expanding(SARIMA_112_101_fun, ts_full, n_train_hours, n_test_days, TRUE),
  SARIMA_211_101 = expanding(SARIMA_211_101_fun, ts_full, n_train_hours, n_test_days, TRUE),
  SARIMA_auto = expanding(SARIMA_auto_fun, ts_full, n_train_hours, n_test_days, TRUE),
  
  ETS = expanding(ETS_fun, ts_full, n_train_hours, n_test_days, TRUE)
)

#plot forecasts:
plot_forecast_simple <- function(forecast_matrix, ts_full, n_train_hours, n_test_days, model_name){
  #format forecasts into a vector
  fc_mean <- as.vector(t(forecast_matrix))
  
  #get actual observations
  hours <- (n_train_hours + 1):(n_train_hours + n_test_days * 24)
  actual <- ts_full[hours]
  
  df_plot <- data.frame(
    hour = hours,
    actual = actual,
    forecast = fc_mean
  )
  
  p <- ggplot(df_plot, aes(x = hour)) +
    geom_line(aes(y = actual), color = "black") +
    geom_line(aes(y = forecast), color = "blue", linetype = "dashed") +
    labs(title = paste("Forecast:", model_name),
         y = "Demand", x = "Hour") +
    theme_minimal()
  
  print(p)
}

#plot rolling forecast:
for(model_name in names(rolling_results)){
  plot_forecast_simple(rolling_results[[model_name]], ts_full, n_train_hours, n_test_days, paste("Rolling -", model_name))
}

#plot expanding forecast:
for(model_name in names(expanding_results)){
  plot_forecast_simple(expanding_results[[model_name]], ts_full, n_train_hours, n_test_days, paste("Expanding -", model_name))
}


##########################
#Out of sample comparison
#######################
#define metrics
MAE <- function(e) mean(abs(e))
RMSE <- function(e) sqrt(mean(e^2))
MAPE <- function(a, f, eps=1e-6) mean(abs((a-f)/(ifelse(a==0,eps,a))))
MASE <- function(a, f, train) mean(abs(a-f)) / mean(abs(diff(train)))

#construct matrix
actual_matrix <- matrix(test_data$demand, nrow=n_test_days, ncol=24, byrow=TRUE)

compute_accuracy <- function(err_mat, fc_mat, train) {
  e <- as.numeric(err_mat)
  a <- as.numeric(actual_matrix)
  f <- as.numeric(fc_mat)
  data.frame(
    MAE = MAE(e),
    RMSE = RMSE(e),
    MASE = MASE(a, f, train),
    MAPE = MAPE(a, f)
  )
}

#compute accuracy for both rolling and expanding
rolling_errors <- lapply(rolling_results, function(fc) actual_matrix - fc)
expanding_errors <- lapply(expanding_results, function(fc) actual_matrix - fc)

rolling_accuracy <- mapply(
  compute_accuracy,
  err_mat = rolling_errors,
  fc_mat = rolling_results,
  MoreArgs = list(train = ts_full[1:n_train_hours]),
  SIMPLIFY = FALSE
)

expanding_accuracy <- mapply(
  compute_accuracy,
  err_mat = expanding_errors,
  fc_mat = expanding_results,
  MoreArgs = list(train = ts_full[1:n_train_hours]),
  SIMPLIFY = FALSE
)

cat("===== Rolling Accuracy =====\n")
print(do.call(rbind, rolling_accuracy))

cat("===== Expanding Accuracy =====\n")
print(do.call(rbind, expanding_accuracy))

#################################
# significance of forecasting results
###################################
#dm test 
naive_mae <- mean(abs(diff(ts_full[1:n_train_hours])))
mase_loss <- function(e, naive_mae) abs(e)/naive_mae

dm_test_mase <- function(error_list, naive_mae) {
  models <- names(error_list)
  K <- length(models)
  dm_mat <- matrix(NA, K, K, dimnames=list(models, models))
  
  for (i in 1:K) for (j in 1:K) {
    if (i == j) next
    e1 <- as.numeric(error_list[[i]])
    e2 <- as.numeric(error_list[[j]])
    good <- complete.cases(e1, e2)
    
    L1 <- mase_loss(e1[good], naive_mae)
    L2 <- mase_loss(e2[good], naive_mae)
    
    if (var(L1 - L2) == 0) next
    
    test <- try(dm.test(L1, L2, h=1, power=1)$p.value, silent=TRUE)
    if (!inherits(test, "try-error")) dm_mat[i,j] <- test
  }
  dm_mat
}

dm_results <- dm_test_mase(rolling_errors, naive_mae)
cat("===== DM Test (MASE Loss) =====\n")
print(dm_results)

#mcs test:
# Here we see that the models with forcast NA values are removed and only auto_sarima stays
loss_matrix <- sapply(rolling_errors, function(e) mase_loss(as.numeric(e), naive_mae))
loss_matrix <- loss_matrix[complete.cases(loss_matrix), ]
zero_var <- apply(loss_matrix,2,var)==0
loss_matrix <- loss_matrix[, !zero_var, drop=FALSE]

mcs_results <- MCSprocedure(Loss=loss_matrix, alpha=0.05, B=2000)
cat("===== MCS Results =====\n")
print(mcs_results)
